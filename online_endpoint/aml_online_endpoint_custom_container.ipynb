{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/brlamore/src/mlflow_server/online_endpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/var/azureml-app/azureml-models/tfserving-mounted/1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AZURE_TENANT_ID = os.environ.get(\"AZURE_TENANT_ID\")\n",
    "AZURE_SUBSCRIPTION_ID = os.environ.get(\"AZURE_SUBSCRIPTION_ID\")\n",
    "AZURE_CLIENT_ID = os.environ.get(\"AZURE_CLIENT_ID\")\n",
    "AZURE_CLIENT_SECRET = os.environ.get(\"AZURE_CLIENT_SECRET\")\n",
    "AZURE_ML_RESOURCE_GROUP = os.environ.get(\"AZURE_ML_RESOURCE_GROUP\")\n",
    "AZURE_ML_WORKSPACE = os.environ.get(\"AZURE_ML_WORKSPACE\")\n",
    "\n",
    "PROJECT_PATH = os.environ.get(\"PROJECT_PATH\")\n",
    "BASE_PATH = os.path.join(PROJECT_PATH, os.environ.get(\"BASE_PATH\"))\n",
    "AML_MODEL_NAME = os.environ.get(\"AML_MODEL_NAME\")\n",
    "ENDPOINT_MODEL_NAME = os.environ.get(\"ENDPOINT_MODEL_NAME\")\n",
    "MODEL_BASE_PATH = os.environ.get(\"MODEL_BASE_PATH\")\n",
    "\n",
    "print(BASE_PATH)\n",
    "# endpoint_path = os.path.join(PROJECT_PATH, BASE_PATH)\n",
    "model_path = os.path.join(MODEL_BASE_PATH, AML_MODEL_NAME, \"1\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p {endpoint_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-22 19:24:47--  https://aka.ms/half_plus_two-model\n",
      "Resolving aka.ms (aka.ms)... 96.17.65.182\n",
      "Connecting to aka.ms (aka.ms)|96.17.65.182|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://azuremlexamples.blob.core.windows.net/models/half_plus_two.tar.gz [following]\n",
      "--2024-07-22 19:24:48--  https://azuremlexamples.blob.core.windows.net/models/half_plus_two.tar.gz\n",
      "Resolving azuremlexamples.blob.core.windows.net (azuremlexamples.blob.core.windows.net)... 20.60.128.132\n",
      "Connecting to azuremlexamples.blob.core.windows.net (azuremlexamples.blob.core.windows.net)|20.60.128.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7554 (7.4K) [application/x-gzip]\n",
      "Saving to: ‘/home/brlamore/src/mlflow_server/online_endpoint/half_plus_two.tar.gz’\n",
      "\n",
      "/home/brlamore/src/ 100%[===================>]   7.38K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-22 19:24:48 (1.62 GB/s) - ‘/home/brlamore/src/mlflow_server/online_endpoint/half_plus_two.tar.gz’ saved [7554/7554]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download a TensorFlow model\n",
    "!wget https://aka.ms/half_plus_two-model -O {BASE_PATH}/half_plus_two.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half_plus_two/\n",
      "half_plus_two/00000123/\n",
      "half_plus_two/00000123/saved_model.pb\n",
      "half_plus_two/00000123/assets/\n",
      "half_plus_two/00000123/assets/license.txt\n",
      "half_plus_two/00000123/assets/foo.txt\n",
      "half_plus_two/00000123/variables/\n",
      "half_plus_two/00000123/variables/variables.index\n",
      "half_plus_two/00000123/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf {BASE_PATH}/half_plus_two.tar.gz -C {BASE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run --rm -d -v /home/brlamore/src/mlflow_server/online_endpoint:/var/azureml-app/azureml-models/tfserving-mounted/1 -p 8501:8501 -e MODEL_BASE_PATH=/var/azureml-app/azureml-models/tfserving-mounted/1 -e MODEL_NAME=half_plus_two  --name=\"tfserving-test\" docker.io/tensorflow/serving:latest sleep 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"docker run --rm -d -v {BASE_PATH}:{model_path} -p 8501:8501 -e MODEL_BASE_PATH={model_path} -e MODEL_NAME={ENDPOINT_MODEL_NAME}  --name=\\\"tfserving-test\\\" docker.io/tensorflow/serving:latest sleep 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*   Trying 127.0.0.1:8501...\n",
      "* Connected to localhost (127.0.0.1) port 8501 (#0)\n",
      "> GET /v1/models/half_plus_two HTTP/1.1\n",
      "> Host: localhost:8501\n",
      "> User-Agent: curl/7.81.0\n",
      "> Accept: */*\n",
      "> \n",
      "* Mark bundle as not supporting multiuse\n",
      "< HTTP/1.1 200 OK\n",
      "< Content-Type: application/json\n",
      "< Date: Tue, 23 Jul 2024 02:47:44 GMT\n",
      "< Content-Length: 156\n",
      "< \n",
      "{\n",
      " \"model_version_status\": [\n",
      "  {\n",
      "   \"version\": \"123\",\n",
      "   \"state\": \"AVAILABLE\",\n",
      "   \"status\": {\n",
      "    \"error_code\": \"OK\",\n",
      "    \"error_message\": \"\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "# Check liveness\n",
    "!curl -v \"http://localhost:8501/v1/models/{ENDPOINT_MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/brlamore/src/mlflow_server/online_endpoint/sample_request.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [2.5, 3.0, 4.5\n",
      "    ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "# Check prediction\n",
    "!echo {BASE_PATH}/sample_request.json\n",
    "!curl --header \"Content-Type: application/json\"   --request POST --data @{BASE_PATH}/sample_request.json http://localhost:8501/v1/models/{ENDPOINT_MODEL_NAME}:predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfserving-test\n"
     ]
    }
   ],
   "source": [
    "!docker stop tfserving-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "credential = DefaultAzureCredential()\n",
    "if not credential:\n",
    "    credential = ClientSecretCredential(\n",
    "        tenant_id=AZURE_TENANT_ID,\n",
    "        client_id=AZURE_CLIENT_ID,\n",
    "        client_secret=AZURE_CLIENT_SECRET,\n",
    "    )\n",
    "    \n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), AZURE_SUBSCRIPTION_ID, AZURE_ML_RESOURCE_GROUP, AZURE_ML_WORKSPACE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"endpoint-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a sample online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://endpoint-07230815437793.westus3.inference.ml.azure.com/score', 'openapi_uri': 'https://endpoint-07230815437793.westus3.inference.ml.azure.com/swagger.json', 'name': 'endpoint-07230815437793', 'description': 'this is a sample online endpoint', 'tags': {'foo': 'bar'}, 'properties': {'createdBy': '0319a625-aacd-4030-af25-09981016d2f1', 'createdAt': '2024-07-23T15:16:07.213121+0000', 'lastModifiedAt': '2024-07-23T15:16:07.213121+0000', 'azureml.onlineendpointid': '/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/resourcegroups/rg_aml/providers/microsoft.machinelearningservices/workspaces/blx_aml/onlineendpoints/endpoint-07230815437793', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/providers/Microsoft.MachineLearningServices/locations/westus3/mfeOperationsStatus/oeidp:22f88b38-6636-4d7c-a9d4-fc0cdeb79f22:70491dfb-5c8d-4c69-b2ff-984261a8ec44?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/resourceGroups/rg_aml/providers/Microsoft.MachineLearningServices/workspaces/blx_aml/onlineEndpoints/endpoint-07230815437793', 'Resource__source_path': '', 'base_path': '/home/brlamore/src/mlflow_server/online_endpoint', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fca7f1db5e0>, 'auth_mode': 'key', 'location': 'westus3', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fca7f37c580>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the endpoint\n",
    "ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a blue deployment\n",
    "model = Model(name=\"tfserving-mounted\", version=\"1\", path=\"half_plus_two\")\n",
    "\n",
    "env = Environment(\n",
    "    image=\"docker.io/tensorflow/serving:latest\",\n",
    "    inference_config={\n",
    "        \"liveness_route\": {\"port\": 8501, \"path\": \"/v1/models/half_plus_two\"},\n",
    "        \"readiness_route\": {\"port\": 8501, \"path\": \"/v1/models/half_plus_two\"},\n",
    "        \"scoring_route\": {\"port\": 8501, \"path\": \"/v1/models/half_plus_two:predict\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    environment_variables={\n",
    "        \"MODEL_BASE_PATH\": \"/var/azureml-app/azureml-models/tfserving-mounted/1\",\n",
    "        \"MODEL_NAME\": \"half_plus_two\",\n",
    "    },\n",
    "    instance_type=\"Standard_F2s_v2\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint endpoint-07230815437793 exists\n",
      "\u001b[32mUploading half_plus_two (0.02 MBs): 100%|██████████| 23647/23647 [00:00<00:00, 145139.76it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineDeployment({'private_network_connection': None, 'package_model': False, 'provisioning_state': 'Succeeded', 'endpoint_name': 'endpoint-07230815437793', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/providers/Microsoft.MachineLearningServices/locations/westus3/mfeOperationsStatus/odidp:22f88b38-6636-4d7c-a9d4-fc0cdeb79f22:59add067-0947-4bc5-8edc-ab68a2114bd5?api-version=2023-04-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/resourceGroups/rg_aml/providers/Microsoft.MachineLearningServices/workspaces/blx_aml/onlineEndpoints/endpoint-07230815437793/deployments/blue', 'Resource__source_path': '', 'base_path': '/home/brlamore/src/mlflow_server/online_endpoint', 'creation_context': <azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.SystemData object at 0x7fca7f1f5ab0>, 'serialize': <msrest.serialization.Serializer object at 0x7fca7f1f5990>, 'model': '/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/resourceGroups/rg_aml/providers/Microsoft.MachineLearningServices/workspaces/blx_aml/models/tfserving-mounted/versions/1', 'code_configuration': None, 'environment': '/subscriptions/f4f99f06-ec30-4601-b84a-6a47929bc9cc/resourceGroups/rg_aml/providers/Microsoft.MachineLearningServices/workspaces/blx_aml/environments/CliV2AnonymousEnvironment/versions/7e45fd6f9df17cb10fec5a7eb6852fcf', 'environment_variables': {'MODEL_BASE_PATH': '/var/azureml-app/azureml-models/tfserving-mounted/1', 'MODEL_NAME': 'half_plus_two', 'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/tfserving-mounted/1'}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7fca7f1f4f40>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7fca7f1f69e0>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fca7f1f6e90>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fca7f1f7100>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_F2s_v2', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
